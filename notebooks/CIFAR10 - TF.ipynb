{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1725028350904,"execution_millis":4758,"deepnote_to_be_reexecuted":false,"cell_id":"deb18ec278aa4691a14c92d69c7288df","deepnote_cell_type":"code"},"source":"import tensorflow_datasets as tfds\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\n# Function to normalize the images\ndef normalize_img(image, label):\n    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n    image = tf.cast(image, tf.float32) / 255.0\n    # Normalizing to mean=0.5 and std=0.5\n    image = (image - 0.5) / 0.5\n    return image, label\n\n# Load CIFAR-10 dataset into ./data-tf directory\ncifar10_data, cifar10_info = tfds.load('cifar10', with_info=True, as_supervised=True, data_dir='./data-tf')\n\n# Extract train and test datasets\ntrain_data, test_data = cifar10_data['train'], cifar10_data['test']\n\n# Normalize the datasets\ntrain_data = train_data.map(normalize_img)\ntest_data = test_data.map(normalize_img)\n\n# Batch the datasets\nbatch_size = 16\ntrain_data = train_data.batch(batch_size)\ntest_data = test_data.batch(batch_size)\n\n# Display dataset information\n# cifar10_info\nprint(\"TensorFlow version: \", tf.version.VERSION)\nprint(\"Keras version: \", keras.__version__)\nnext(iter(train_data))[1]","block_group":"98e4327704424217997888aaeb0ab567","execution_count":null,"outputs":[{"name":"stderr","text":"2024-08-30 14:32:31.583503: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2024-08-30 14:32:31.586253: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2024-08-30 14:32:31.596489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-30 14:32:31.609822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-30 14:32:31.613276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-08-30 14:32:31.623937: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-08-30 14:32:32.656146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nTensorFlow version:  2.17.0\nKeras version:  3.5.0\n2024-08-30 14:32:35.641540: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"<tf.Tensor: shape=(16,), dtype=int64, numpy=array([7, 8, 4, 4, 6, 5, 2, 9, 6, 6, 9, 9, 3, 0, 8, 7])>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/a49cba71-ac24-4106-80a9-4027a27db4db","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"3d279a782631491da6258cccf80c5612","deepnote_cell_type":"text-cell-p"},"source":"The CIFAR-10 dataset has been successfully loaded using TensorFlow Datasets. The dataset contains 50,000 training examples and 10,000 test examples, each with 32x32 color images in 10 different classes.","block_group":"3ffb4e605d084aa2b70c9e2094dd2a6c"},{"cell_type":"markdown","metadata":{"color":"purple","formattedRanges":[],"cell_id":"1c0fa0e259364691ad2994129c6bea3c","deepnote_cell_type":"text-cell-callout"},"source":"> create network in tf without using keras:\nclass Net(nn.Module):\n    SLOPE = 0.01\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)","block_group":"8914ec36f8864820ba09c5df529b1732"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724909285194,"execution_millis":151,"deepnote_to_be_reexecuted":false,"cell_id":"0e595a3da7ec451a80e73e542b1453f5","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\nclass Net(tf.Module):\n    SLOPE = 0.01\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = tf.Variable(tf.random.normal([5, 5, 3, 6]), name='conv1')\n        self.conv2 = tf.Variable(tf.random.normal([5, 5, 6, 16]), name='conv2')\n        self.fc1 = tf.Variable(tf.random.normal([16 * 5 * 5, 120]), name='fc1')\n        self.fc2 = tf.Variable(tf.random.normal([120, 84]), name='fc2')\n        self.fc3 = tf.Variable(tf.random.normal([84, 10]), name='fc3')\n        self.pool = tf.nn.max_pool2d\n\n    def __call__(self, x):\n        x = tf.nn.conv2d(x, self.conv1, strides=[1, 1, 1, 1], padding='VALID')\n        x = tf.nn.relu(x)\n        x = self.pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n        x = tf.nn.conv2d(x, self.conv2, strides=[1, 1, 1, 1], padding='VALID')\n        x = tf.nn.relu(x)\n        x = self.pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n        x = tf.reshape(x, [-1, 16 * 5 * 5])\n        x = tf.matmul(x, self.fc1)\n        x = tf.nn.leaky_relu(x, alpha=self.SLOPE)\n        x = tf.matmul(x, self.fc2)\n        x = tf.nn.leaky_relu(x, alpha=self.SLOPE)\n        x = tf.matmul(x, self.fc3)\n        return x\n\n# Instantiate the network\nnet = Net()","block_group":"80e20f5423394ce5989eaadfa9bd7e7e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6fd758d1ca434feea634c61a3f95aa75","deepnote_cell_type":"text-cell-p"},"source":"The convolutional neural network has been successfully created using TensorFlow without Keras. The network is instantiated and ready for use.","block_group":"30d6dbd5cafc46c48a095bfa6c38ab85"},{"cell_type":"markdown","metadata":{"color":"purple","cell_id":"21c6b5d3a75b419abc9d6ac37f070fc1","deepnote_cell_type":"text-cell-callout"},"source":"> write training loop input = test_data, network = net, 1 epoch, print average loss","block_group":"9a5679740d874bb19634e13d1f4410c8"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724910327809,"execution_millis":103,"deepnote_to_be_reexecuted":false,"cell_id":"af5a10d413f3464a847bb359dc9e90a6","deepnote_cell_type":"code"},"source":"# Define the training loop and Train the network for one epoch\n\ndef train_one_epoch(dataset, model, optimizer, loss_fn):\n    total_loss = 0.0\n    num_batches = 0\n\n    for images, labels in dataset:\n        with tf.GradientTape() as tape:\n            outputs = model(images)\n            loss = loss_fn(labels, outputs)\n        \n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n        \n        total_loss += loss.numpy()\n        num_batches += 1\n\n    average_loss = total_loss / num_batches\n    return average_loss\n\n# Set up the optimizer and loss function\noptimizer = tf.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999)\ncriterion = tf.losses.SparseCategoricalCrossentropy(from_logits=True)","block_group":"3dbd4bfa9c4744788210ed062beb3304","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724910331881,"execution_millis":126093,"deepnote_to_be_reexecuted":false,"cell_id":"19e576a8cf4042fc9976f8f2727069fb","deepnote_cell_type":"code"},"source":"# Train for 6 epochs\nnum_epochs = 6\nfor epoch in range(num_epochs):\n    average_loss = train_one_epoch(test_data, net, optimizer, criterion)\n    print(f'Epoch {epoch + 1}, Average Loss: {average_loss:.4f}')\n    \n# Output the final average loss\naverage_loss","block_group":"314ca07620364cd8b429f558a776dd93","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1, Average Loss: 1.8258\nEpoch 2, Average Loss: 1.8132\n2024-08-29 05:46:33.090707: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\nEpoch 3, Average Loss: 1.8058\nEpoch 4, Average Loss: 1.8046\nEpoch 5, Average Loss: 1.8032\nEpoch 6, Average Loss: 1.7917\n","output_type":"stream"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"1.791662993812561"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/67af5883-7b08-44e5-8000-6744ed8c9233","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"bdcc154b41d84d9d97f24d8d5e84bc13","deepnote_cell_type":"text-cell-h2"},"source":"## Save trained model","block_group":"6d8ed6e5247f41ecbcdbcd2d920388ba"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724842233986,"execution_millis":2191,"deepnote_to_be_reexecuted":false,"cell_id":"6a527bf5bf354f37b2739f79c3504798","deepnote_cell_type":"code"},"source":"# Save the trained model\nimport tensorflow as tf\n\n# Save the model weights\ncheckpoint = tf.train.Checkpoint(model=net)\ncheckpoint.save('cifar10_model.ckpt')","block_group":"1ff159ceb6a04ae393c3e69b3a07be58","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"'cifar10_model.ckpt-1'"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/5eeefc86-cf22-46f8-a2d2-291f9528e6ce","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"8e58c79132534c178cda1eb4aa5299cb","deepnote_cell_type":"text-cell-p"},"source":"The trained model has been saved as `cifar10_model.ckpt-1`.","block_group":"6aecde8c55dd4144ba1a88a5f9cc5ae0"},{"cell_type":"markdown","metadata":{"color":"purple","cell_id":"a40249ed9f964b50ac1d04b63547818e","deepnote_cell_type":"text-cell-callout"},"source":"> load data model from 'cifar10_model.ckpt'","block_group":"df953482c8d5479ab2463fea2ea3cd92"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724910284798,"execution_millis":1531,"deepnote_to_be_reexecuted":false,"cell_id":"5fc37f1ccce34fa4bcc91d752ea0578a","deepnote_cell_type":"code"},"source":"# Load the trained model from the checkpoint\ncheckpoint = tf.train.Checkpoint(model=net)\ncheckpoint.restore('cifar10_model.ckpt-1')\n\n# Verify that the model has been loaded correctly by running a test image through it\nfor image, label in test_data.take(1).cache():\n    output = net(image)\n    # Display output of only 1 classification\n    print(\"Raw output:\", output[0])\n    # Compute the softmax of output\n    softmax_output = tf.nn.softmax(output)\n    print(\"Softmax output:\", softmax_output[0])","block_group":"b63bcf7b45af418f8af4df0d9d9df0b6","execution_count":null,"outputs":[{"name":"stdout","text":"Raw output: tf.Tensor(\n[-138.09183 -137.39015 -136.01796 -135.43976 -134.64357 -135.36809\n -134.70815 -135.31839 -139.15324 -137.35419], shape=(10,), dtype=float32)\nSoftmax output: tf.Tensor(\n[0.00834945 0.01684191 0.0664243  0.11842314 0.2625529  0.12722215\n 0.2461343  0.13370456 0.00288862 0.01745865], shape=(10,), dtype=float32)\n2024-08-29 05:44:46.324797: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d633928d-e43e-4a85-9a1f-c465e0ab4397","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"4c9cdb0045754afe92992053e7d1350e","deepnote_cell_type":"text-cell-p"},"source":"The model has been successfully loaded from the checkpoint and verified by running a test image through it.","block_group":"75c21729443441ee8279b94487212b97"},{"cell_type":"markdown","metadata":{"color":"purple","cell_id":"9f34bfa59d9248db849e1c01389fdee7","deepnote_cell_type":"text-cell-callout"},"source":"> evaluate accuracy on test set per each class","block_group":"8dddd3aee18147f79b4dff428168bdf1"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724910293028,"execution_millis":7600,"deepnote_to_be_reexecuted":false,"cell_id":"fed202ee055c4c6f9a32b2bbc1f8bd0f","deepnote_cell_type":"code"},"source":"# Evaluate accuracy on the test set per each class\n\n# Function to calculate accuracy per class\nimport numpy as np\n\ndef evaluate_accuracy_per_class(model, dataset, num_classes=10):\n    class_correct = np.zeros(num_classes)\n    class_total = np.zeros(num_classes)\n\n    for images, labels in dataset:\n        outputs = model(images)\n        _, predicted = tf.math.top_k(outputs, 1)\n        predicted = tf.squeeze(predicted, axis=1)\n        correct = tf.equal(predicted, tf.cast(labels, tf.int32))\n\n        for i in range(len(labels)):\n            label = labels[i].numpy()\n            class_correct[label] += correct[i].numpy()\n            class_total[label] += 1\n\n    class_accuracy = [class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(num_classes)]\n    return class_accuracy\n\n# Evaluate the model on the test set\nclass_accuracy = evaluate_accuracy_per_class(net, test_data)\nclass_accuracy","block_group":"64e68c4bda454cf29ea0232f8ca0c4c6","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"[0.539, 0.388, 0.331, 0.333, 0.273, 0.239, 0.462, 0.091, 0.426, 0.557]"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/b42bbf29-9cd1-48c9-96df-5a25d5d8e5fe","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=96230c3c-90f8-4675-a637-f681b2b6286f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"0e585b8c049e4f94ab1fb80cd7f3b78c","deepnote_execution_queue":[]}}