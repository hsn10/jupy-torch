{"cells":[{"cell_type":"markdown","metadata":{"color":"yellow","formattedRanges":[],"cell_id":"d05a17d99eb64c88883b12449fa4029a","deepnote_cell_type":"text-cell-callout"},"source":"> load cifar10 dataset to pytorch, use constant BATCH_SIZE and number of workers","block_group":"f6f3c690af7c468886379be629b0d516"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1725254713453,"execution_millis":11639,"deepnote_to_be_reexecuted":false,"cell_id":"11731698a07d4edea4194435e51ff4cf","deepnote_cell_type":"code"},"source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Constants\nBATCH_SIZE = 16\nNUM_WORKERS = 2\n\n# Transformations\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# Load CIFAR10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n                                          shuffle=True, num_workers=NUM_WORKERS)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n                                         shuffle=False, num_workers=NUM_WORKERS)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# (trainset, trainloader, testset, testloader, classes)\nprint(\"CIFAR10 train:\", len(trainset), \"test:\", len(testset));","block_group":"0437e8f6e1b049e0bbe90f2f526954ad","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.10/py/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nFiles already downloaded and verified\nFiles already downloaded and verified\nCIFAR10 train: 50000 test: 10000\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b2410ae2-50a2-48a3-a908-3215623fda00","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1725215916112,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"3e64bb8af6494fe5899c464e271a8154","deepnote_cell_type":"code"},"source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# Define a simple CNN model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n        #init Conv2d\n        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","block_group":"563342c76b80447997241ff53e1a6152","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"color":"purple","cell_id":"51158f96c49642eea8b4ef39fff27f09","deepnote_cell_type":"text-cell-callout"},"source":"> create training loop with Ignite, adamw optimizer, 1e-4 learning rate","block_group":"d8286520ee3c49b6a081fc058187eb58"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1725035077264,"execution_millis":1050459,"deepnote_to_be_reexecuted":false,"cell_id":"50ec0d5be8cf4e369b37b83405eff3ee","deepnote_cell_type":"code"},"source":"from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import ModelCheckpoint\nfrom torch.optim import AdamW\nimport time\n\n# Instantiate the model, loss function, and optimizer\nmodel = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = AdamW(model.parameters(), lr=1e-3)\n\n# Create Ignite trainer and evaluator\ntrainer = create_supervised_trainer(model, optimizer, criterion, device='cpu')\nevaluator = create_supervised_evaluator(model, metrics={'accuracy': Accuracy(), 'loss': Loss(criterion)}, device='cpu')\n\n# Attach event handlers to log training progress\n@trainer.on(Events.ITERATION_COMPLETED(every=2000))\ndef log_training_loss(engine):\n    print(f\"Epoch[{engine.state.epoch}] Iteration[{engine.state.iteration}] Loss: {engine.state.output:.2f}\")\n\n@trainer.on(Events.EPOCH_STARTED)\ndef start_epoch_timer(engine):\n    engine.state.epoch_start_time = time.time()\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(engine):\n    evaluator.run(trainloader)\n    metrics = evaluator.state.metrics\n    print(f\"Training Results - Epoch: {engine.state.epoch}  Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n    # Log time elapsed\n    epoch_duration = time.time() - engine.state.epoch_start_time\n    print(f\"Time elapsed for epoch {engine.state.epoch}: {epoch_duration:.1f} seconds\")\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_validation_results(engine):\n    evaluator.run(testloader)\n    metrics = evaluator.state.metrics\n    print(f\"Validation Results - Epoch: {engine.state.epoch}  Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef save_checkpoint(engine):\n    # Create a checkpoint handler\n    checkpoint_handler = ModelCheckpoint(\n    dirname='./checkpoints',\n    filename_prefix='cifar10',\n    n_saved=2,\n    create_dir=True,\n    require_empty=False,\n    atomic=True,\n    include_self=True\n    )\n    checkpoint_handler(engine, {'model': model, 'optimizer': optimizer, 'trainer': trainer})\n\n@trainer.on(Events.COMPLETED)\ndef save_final_model(engine):\n    torch.save(model.state_dict(), 'cifar10.pth')\n    \n# Run the training loop\ntrainer.run(trainloader, max_epochs=10)","block_group":"635c54b3aed8481bb811bb2ce4d988af","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch[1] Iteration[2000] Loss: 1.56\nTraining Results - Epoch: 1  Avg accuracy: 0.53 Avg loss: 1.31\nTime elapsed for epoch 1: 98.0 seconds\nValidation Results - Epoch: 1  Avg accuracy: 0.52 Avg loss: 1.35\nEpoch[2] Iteration[4000] Loss: 1.01\nEpoch[2] Iteration[6000] Loss: 1.25\nTraining Results - Epoch: 2  Avg accuracy: 0.60 Avg loss: 1.12\nTime elapsed for epoch 2: 93.1 seconds\nValidation Results - Epoch: 2  Avg accuracy: 0.57 Avg loss: 1.21\nEpoch[3] Iteration[8000] Loss: 1.45\nTraining Results - Epoch: 3  Avg accuracy: 0.61 Avg loss: 1.11\nTime elapsed for epoch 3: 94.2 seconds\nValidation Results - Epoch: 3  Avg accuracy: 0.57 Avg loss: 1.22\nEpoch[4] Iteration[10000] Loss: 0.62\nEpoch[4] Iteration[12000] Loss: 0.92\nTraining Results - Epoch: 4  Avg accuracy: 0.65 Avg loss: 0.99\nTime elapsed for epoch 4: 96.5 seconds\nValidation Results - Epoch: 4  Avg accuracy: 0.60 Avg loss: 1.14\nEpoch[5] Iteration[14000] Loss: 1.00\nTraining Results - Epoch: 5  Avg accuracy: 0.67 Avg loss: 0.93\nTime elapsed for epoch 5: 96.1 seconds\nValidation Results - Epoch: 5  Avg accuracy: 0.61 Avg loss: 1.12\nEpoch[6] Iteration[16000] Loss: 0.98\nEpoch[6] Iteration[18000] Loss: 1.10\nTraining Results - Epoch: 6  Avg accuracy: 0.68 Avg loss: 0.90\nTime elapsed for epoch 6: 94.2 seconds\nValidation Results - Epoch: 6  Avg accuracy: 0.61 Avg loss: 1.11\nEpoch[7] Iteration[20000] Loss: 1.19\nTraining Results - Epoch: 7  Avg accuracy: 0.69 Avg loss: 0.87\nTime elapsed for epoch 7: 96.6 seconds\nValidation Results - Epoch: 7  Avg accuracy: 0.61 Avg loss: 1.12\nEpoch[8] Iteration[22000] Loss: 1.12\nEpoch[8] Iteration[24000] Loss: 0.51\nTraining Results - Epoch: 8  Avg accuracy: 0.70 Avg loss: 0.85\nTime elapsed for epoch 8: 100.2 seconds\nValidation Results - Epoch: 8  Avg accuracy: 0.61 Avg loss: 1.12\nEpoch[9] Iteration[26000] Loss: 1.35\nEpoch[9] Iteration[28000] Loss: 0.84\nTraining Results - Epoch: 9  Avg accuracy: 0.72 Avg loss: 0.78\nTime elapsed for epoch 9: 96.9 seconds\nValidation Results - Epoch: 9  Avg accuracy: 0.63 Avg loss: 1.09\nEpoch[10] Iteration[30000] Loss: 1.07\nTraining Results - Epoch: 10  Avg accuracy: 0.71 Avg loss: 0.82\nTime elapsed for epoch 10: 96.1 seconds\nValidation Results - Epoch: 10  Avg accuracy: 0.61 Avg loss: 1.16\n","output_type":"stream"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"State:\n\titeration: 31250\n\tepoch: 10\n\tepoch_length: 3125\n\tmax_epochs: 10\n\toutput: 0.7039793729782104\n\tbatch: <class 'list'>\n\tmetrics: <class 'dict'>\n\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n\tseed: <class 'NoneType'>\n\ttimes: <class 'dict'>\n\tepoch_start_time: 1725036022.1734416"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/0267cb20-77e6-4245-afe0-1911f10d70ce","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=96230c3c-90f8-4675-a637-f681b2b6286f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"dbd6815ad8af40c59cecd59d8704a6e5","deepnote_execution_queue":[]}}