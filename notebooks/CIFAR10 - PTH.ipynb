{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d05a17d99eb64c88883b12449fa4029a",
    "color": "yellow",
    "deepnote_cell_type": "text-cell-callout",
    "formattedRanges": []
   },
   "source": [
    "> load cifar10 dataset to pytorch, use constant BATCH_SIZE and number of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "11731698a07d4edea4194435e51ff4cf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11639,
    "execution_start": 1725254713453,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# (trainset, trainloader, testset, testloader, classes)\n",
    "print(\"CIFAR10 train:\", len(trainset), \"test:\", len(testset));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3e64bb8af6494fe5899c464e271a8154",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1725215916112,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        #init Conv2d\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "51158f96c49642eea8b4ef39fff27f09",
    "color": "purple",
    "deepnote_cell_type": "text-cell-callout"
   },
   "source": [
    "> create training loop with Ignite, adamw optimizer, 1e-4 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "50ec0d5be8cf4e369b37b83405eff3ee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1050459,
    "execution_start": 1725035077264,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[2000] Loss: 1.56\n",
      "Training Results - Epoch: 1  Avg accuracy: 0.53 Avg loss: 1.31\n",
      "Time elapsed for epoch 1: 98.0 seconds\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.52 Avg loss: 1.35\n",
      "Epoch[2] Iteration[4000] Loss: 1.01\n",
      "Epoch[2] Iteration[6000] Loss: 1.25\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.60 Avg loss: 1.12\n",
      "Time elapsed for epoch 2: 93.1 seconds\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.57 Avg loss: 1.21\n",
      "Epoch[3] Iteration[8000] Loss: 1.45\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.61 Avg loss: 1.11\n",
      "Time elapsed for epoch 3: 94.2 seconds\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.57 Avg loss: 1.22\n",
      "Epoch[4] Iteration[10000] Loss: 0.62\n",
      "Epoch[4] Iteration[12000] Loss: 0.92\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.65 Avg loss: 0.99\n",
      "Time elapsed for epoch 4: 96.5 seconds\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.60 Avg loss: 1.14\n",
      "Epoch[5] Iteration[14000] Loss: 1.00\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.67 Avg loss: 0.93\n",
      "Time elapsed for epoch 5: 96.1 seconds\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.61 Avg loss: 1.12\n",
      "Epoch[6] Iteration[16000] Loss: 0.98\n",
      "Epoch[6] Iteration[18000] Loss: 1.10\n",
      "Training Results - Epoch: 6  Avg accuracy: 0.68 Avg loss: 0.90\n",
      "Time elapsed for epoch 6: 94.2 seconds\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.61 Avg loss: 1.11\n",
      "Epoch[7] Iteration[20000] Loss: 1.19\n",
      "Training Results - Epoch: 7  Avg accuracy: 0.69 Avg loss: 0.87\n",
      "Time elapsed for epoch 7: 96.6 seconds\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.61 Avg loss: 1.12\n",
      "Epoch[8] Iteration[22000] Loss: 1.12\n",
      "Epoch[8] Iteration[24000] Loss: 0.51\n",
      "Training Results - Epoch: 8  Avg accuracy: 0.70 Avg loss: 0.85\n",
      "Time elapsed for epoch 8: 100.2 seconds\n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.61 Avg loss: 1.12\n",
      "Epoch[9] Iteration[26000] Loss: 1.35\n",
      "Epoch[9] Iteration[28000] Loss: 0.84\n",
      "Training Results - Epoch: 9  Avg accuracy: 0.72 Avg loss: 0.78\n",
      "Time elapsed for epoch 9: 96.9 seconds\n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.63 Avg loss: 1.09\n",
      "Epoch[10] Iteration[30000] Loss: 1.07\n",
      "Training Results - Epoch: 10  Avg accuracy: 0.71 Avg loss: 0.82\n",
      "Time elapsed for epoch 10: 96.1 seconds\n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.61 Avg loss: 1.16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 31250\n",
       "\tepoch: 10\n",
       "\tepoch_length: 3125\n",
       "\tmax_epochs: 10\n",
       "\toutput: 0.7039793729782104\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>\n",
       "\tepoch_start_time: 1725036022.1734416"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Create Ignite trainer and evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device='cpu')\n",
    "evaluator = create_supervised_evaluator(model, metrics={'accuracy': Accuracy(), 'loss': Loss(criterion)}, device='cpu')\n",
    "\n",
    "# Attach event handlers to log training progress\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=2000))\n",
    "def log_training_loss(engine):\n",
    "    print(f\"Epoch[{engine.state.epoch}] Iteration[{engine.state.iteration}] Loss: {engine.state.output:.2f}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def start_epoch_timer(engine):\n",
    "    engine.state.epoch_start_time = time.time()\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(trainloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Training Results - Epoch: {engine.state.epoch}  Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
    "    # Log time elapsed\n",
    "    epoch_duration = time.time() - engine.state.epoch_start_time\n",
    "    print(f\"Time elapsed for epoch {engine.state.epoch}: {epoch_duration:.1f} seconds\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(testloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Validation Results - Epoch: {engine.state.epoch}  Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def save_checkpoint(engine):\n",
    "    # Create a checkpoint handler\n",
    "    checkpoint_handler = ModelCheckpoint(\n",
    "    dirname='./checkpoints',\n",
    "    filename_prefix='cifar10',\n",
    "    n_saved=2,\n",
    "    create_dir=True,\n",
    "    require_empty=False,\n",
    "    atomic=True,\n",
    "    include_self=True\n",
    "    )\n",
    "    checkpoint_handler(engine, {'model': model, 'optimizer': optimizer, 'trainer': trainer})\n",
    "\n",
    "@trainer.on(Events.COMPLETED)\n",
    "def save_final_model(engine):\n",
    "    torch.save(model.state_dict(), 'cifar10.pth')\n",
    "    \n",
    "# Run the training loop\n",
    "trainer.run(trainloader, max_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dbd6815ad8af40c59cecd59d8704a6e5",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
